---
title: "bmstdr: Bayesian Modeling of Spatio-Temporal Data with R"
output: 
   BiocStyle::html_document:
   BiocStyle::pdf_document:
bibliography: bigref.bib
number_sections: true
author: 
- name: Sujit K. Sahu
  affiliation:  University of Southampton
  email: S.K.Sahu@soton.ac.uk 
package: bmstdr
abstract: >
  This is a vignette for the `R` package `bmstdr`. The package facilitates Bayesian modeling of both point reference and areal unit data with or without temporal replications. Three main functions in the package: `Bspatial` for spatial only point referene data,   `Bsptime` for spatio-temporal point reference data  and `Bcartime` for  areal unit data,  which may also vary in time,  perform the main modeling and validation tasks. Computations and inference in a Bayesian modeling framework   are done using popular `R` software packages such as `spBayes`, `spTimer`, `INLA`, `rstan`, `spTDyn`, `CARBayes` and `CARBayesST`. Point reference data are modeled using the Gaussian error distribution only but a top level  generalized linear model is used for areal data modeling. The user of `bmstdr` is afforded the flexibility to choose an appropriate package and is also free to name the rows of their input data frame for validation  purposes. The package  incorporates a range of prior distributions allowable in the nominated  packages with default hyperparameter values.   The package allows quick comparison of models using both model choice criteria,  such as DIC  and WAIC,  and K-fold cross-validation. Familiar diagnostic plots and model fit exploration using the S3 methods such as  `summary`, `residuals` and `plot` are included so that a beginner user  confident in model fitting using the base `R` function  `lm` can quickly graduate to analyzing data by fitting  a range of appropriate spatial and spatio-temporal models.  This vignette illustrates the package using four built-in data sets: two on point reference data and two others on areal data on Covid-19 mortality in England. 
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{bmstdr}
  %\VignetteEngine{knitr::rmarkdown}
---
```{r style, echo = FALSE, results = 'asis'}
  BiocStyle::markdown()
```
  
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
```
<!--opts_chunk$set(fig.path = "inst/figs/") -->

```{r setup,  echo=FALSE, include=FALSE}
library(bmstdr)
library(ggplot2)
require(databmstdr)
require(ggsn)
# output: rmarkdown::html_vignette
```
```{r echo=FALSE}
knitr::opts_chunk$set(eval = F)
# knitr::opts_knit$set(root.dir ='~/Dropbox/sks/bookproject/rbook/Rfiles')
```
<!--withBraces    <- "\\newcommand{\\withBraces}{This is a sentence.}" -->

<!-- # https://stackoverflow.com/questions/34029611/how-to-use-objects-from-global-environment-in-rstudio-markdown -->


# Introduction 

Bayesian modeling of spatial and spatio-temporal data is essential in many applied areas of research such as atmospheric sciences, climatology, ecology, environmental health and  oceanography. Such diversity in application areas is being serviced by the rich diversity of `R` contributed packages listed in the abstract and many others. The diversity in packages, however, is also a source of challenge for a typical applied scientist. The challenge comes from the essential requirement to  learn the package specific commands and prior distributions that are to be used for the applied problem at hand. 

The current package `bmstdr` sets out to help  researchers in applied sciences model a large variety of spatial and spatio-temporal data using a multiplicity of packages but by using only three commands with different options. Point reference spatial data, where each observation comes with a single geo-coded location reference such as a latitude-longitude pair, can be analyzed by fitting several spatial   and spatio-temporal models using `R` software packages such as
`r CRANpkg("spBayes")` [@spBayes],  `r CRANpkg("spTimer")` [@spTimer],  `r Rpackage("INLA")` [@Rue_inla], 
`r CRANpkg("rstan")` [@rstan],  and `r CRANpkg("spTDyn")` [@Bakaretal_spTdynamic].  
A particular package is chosen with the `package=` option to the `bmstdr` model fitting  routines `Bspatial` for point reference spatial only data and
`Bsptime` for spatio-temporal data. In each of these cases a Bayesian linear model, which can be fitted with the option `package="none"` provides a base line for model comparison purposes. For areal unit data modeling the `bmstdr` function `Bcartime` provides opportunities for model fitting using three packages: 
`r CRANpkg("CARBayes")` [@LeeCARBayes2021],  `r CRANpkg("CARBayesST")` [@CarBayesST] and `r Rpackage("INLA")` [@blangiardoandcameletti]. Here also a base line Bayesian generalized linear model for independent data, fitted using `CARBayes`,  is included for model comparison purposes. 

Models fitted using `bmstdr` can be validated using the optional argument `validrows`, which can be a vector of row numbers of the model fitting data  frame, to any of the three model fitting functions. The package then automatically sets aside the nominated data rows as specified by the `validrows` argument and use the remaining data rows for model fitting. Inclusion of this argument also automatically triggers calculation of four popular model validation statistics: root mean square error, mean absolute error, continuous ranked probability score [@gneiting2007] and coverage percentage. While performing validation the package also produces a scatter plot of predictions against observations with further options controlling the behavior of this plot. 


The remainder of this vignette is organized as follows. Section \@ref(point-reference-spatial-data-modeling)  illustrates point reference spatial data modeling with Gaussian error distribution. 
Section \@ref(point-reference-spatio-temporal-data-modeling) discusses Gaussian 
models for point reference spatio-temporal data. Area data are modeled in Section 
\@ref(modeling-areal-unit-data) where Section \@ref(modeling-static-areal-unit-data) illustrates models for static areal unit data and Section   \@ref(modeling-temporal-areal-unit-data) considers areal temporal data. Some summary remarks are provided in Section  \@ref(discussion). 



# Point reference spatial data modeling
  
## Illustration data set nyspatial

To illustrate point reference spatio-temporal data modeling we use the `nyspatial` data set included in the package. This data set has 28 rows and 9 columns containing average ground level ozone air pollution data from 28 sites in the state of New York. The averages are taken over the 62 days in July and August 2006. The full spatio-temporal data set from 28 sites for 62 days is used to illustrate 
spatio-temporal modeling, see Section  \@ref(illustration-data-set-nysptime). 
Figure \@ref(fig:nysites) represents a map of the state of New York  
together with the 28 monitoring locations.  


```{r nysites, fig.cap="28 air pollution monitoring sites in New York", echo=FALSE, eval=TRUE}
defaultW <- getOption("warn") 
options(warn = -1) 
nymap <- map_data(database="state",regions="new york")
p <- ggplot() +
  geom_polygon(data=nymap, aes(x=long, y=lat, group=group),
               color="black", size = 0.6, fill=NA) +
  geom_point(data =nyspatial, aes(x=Longitude,y=Latitude)) +
  labs(x="Longitude", y ="Latitude") +
  scalebar(data =nymap, dist = 100, location = "bottomleft", transform=T, dist_unit = "km",
                 st.dist = .05, st.size = 5, height = .06, st.bottom=T, model="WGS84") +
  north(data=nymap, location="topleft", symbol=12)
p
options(warn = defaultW)
```

For regression modeling purposes, the response variable is `yo3` and the three important covariates are maximum temperature: `xmaxtemp` in degree Celsius, wind speed: `xwdsp` in nautical miles and  percentage average relative humidity: `xrh`.
This data set is included in the package and further information regarding this can be obtained from the help file `?nyspatial`. 


## The Bspatial function for fitting spatial regression models

The `bmstdr` package includes the function `Bspatial` for fitting regression models to point referenced spatial data.
 The arguments to this function has been documented in the help file which can be viewed by issuing the `R` command `?Bspatial`. The package manual also contains the full documentation. The discussion below highlights the 
 main features of this model fitting function. 
 
 Besides the usual `data` and `formula` the argument `scale.transform` can take one of three possible values:
 `NONE, SQRT` and `LOG`. This  argument defines the on the fly transformation for the response variable which 
 appears on the left hand side of the formula.
 
  Default values of the arguments `prior.beta0, prior.M` and `prior.sigma2` defining the prior
 distributions for $\mathbf{\beta}$ and $1/\sigma^2$ are provided.
 
 The options `model="lm"`  and  `model="spat"`
 are respectively used for fitting and analysis using the independent spatial regression model with 
 exponential correlation function.  If the latter regression model is to be fitted, the function requires 
  three additional arguments, `coordtype`, `coords` and `phi`. The `coords` argument provides the 
  coordinates of the data locations. The type of these coordinates, specified by
 the `coordtype` argument, taking one of three possible values: `utm`, `lonlat` and `plain`
 determines various aspects of  distance calculation and hence model fitting. 
 The default for this argument is `utm` when it is expected that the coordinates are supplied in units of meter. 
 The `coords` argument provides the actual coordinate values and this argument  can be supplied as a vector of 
 size two identifying the two column numbers of the data frame to take as coordinates. Or this argument
 can be given as a matrix of number of sites by 2 providing the coordinates of all the data locations.

 The parameter `phi` determines the rate of decay of the spatial correlation for the assumed
 exponential covariance function. The default value, if not provided, is taken to be 3 over the
 maximum distance between the data locations so that the effective range is
 the maximum distance.

The argument `package` chooses one package to fit the spatial model from among four possible choices. The default option `none` is used to fit the independent linear regression model and the also the spatial regression model without the nugget effect when the parameter `phi` is assumed to be known. The three other options are 
`spBayes, stan` and `inla`. Each of these options use the corresponding 
R packages for model fitting. The exact form of the models in each case is documented in Chapter 6 of the book @Sahubook. 

 
 Calculation of model choice statistics is triggered by the option `mchoice=T`. In this case the DIC, WAIC and PMCC
 values are calculated. 
 
 An optional vector argument `validrows` providing the row numbers of the supplied data frame for 
 model validation can also be given. The model choice statistics are calculated on the opted scale 
 but model validations and their uncertainties are calculated on the original scale of the response for ease of interpretation. This strategy of a possible transformed modeling scale but predictions on the original scale is adopted throughout the package. 

 There are other arguments of  `Bspatial`, e.g. `verbose`,  which control various
 aspects of model fitting and return values. Some of these other arguments are only relevant for specifying prior
 distributions and performing specific tasks as we will see throughout the remainder of this section. 
  
 The return value of `Bspatial` is a list of class `bmstdr`  providing  parameter estimates, and if requested model choice statistics and validation predictions
 and statistics. The S3methods `print, plot, summary, fitted`, and `residuals` have been
 implemented for objects of the `bmstdr` class.  Thus the user can give the commands 
 such as `summary(M1)` and `plot(M1)` where `M1` is the model fitted object .  
 

## Fitting independent error regression models

The `bmstdr` package allows us to fit the base linear regression model given by: 
\begin{equation}
Y_i =  \beta_1 x_{i1} + \ldots + \beta_p x_{ip} + \epsilon_i, 
i=1, \ldots, n  (\#eq:multireg)
\end{equation}
where $\beta_1, \ldots, \beta_p$ are unknown regression coefficients and $\epsilon_i$ is the error term that we assume to
follow the normal distribution with mean zero and variance $\sigma^2$. The usual linear model assumes the errors  $\epsilon_i$ to be independent  for $i=1, \ldots, n$.
With the suitable default assumptions regarding the prior distributions we can fit the above
model \@ref(eq:multireg) by using the following command: 
```{r}
M1 <- Bspatial(formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, mchoice=T)
```

  
## Fitting linear models with spatial error distribution
The independent linear regression model \@ref(eq:multireg) is now extended to have 
spatially colored covariance matrix $\sigma^{2}H$ where   $H$ is a known correlation matrix of  the error vector $\mathbf{\epsilon}$, i.e. $H_{ij}=\mbox{Cor}(\epsilon_i, \epsilon_j)$ for $i, j=1, \ldots,n$, 
\begin{equation}
  {\bf Y} \sim N_n \left(X{\mathbf \beta}, \sigma^{2}H\right)
  (\#eq:veclinearmod)
\end{equation}
Assuming the exponential correlation function, i.e., $H_{ij} = \exp(-\phi d_{ij})$ where $d_{ij}$ is the distance between locations $i$ and $j$ we can fit the model  \@ref(eq:veclinearmod) by issuing the command:  
```{r}
M2 <- Bspatial(model="spat", formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, 
      coordtype="utm", coords=4:5, phi=0.4, mchoice=T)
```
We discuss the choice of the fixed value of the spatial decay parameter $\phi=0.4$ in `M2`.  We use cross-validation methods to find an optimal value for $\phi$. We take a grid of values for $\phi$ and calculate a cross-validation error statistics, e.g. root mean square-error (rmse),  for each value of $\phi$ in the grid. The optimal $\phi$ is the one that minimizes the statistics.

To perform the grid search a simple `R` function,  `phichoice_sp` is provided especially for the `nyspatial` data set. The documentation of this function explains how to set the other arguments. For example, the following commands work:
```{r, echo=TRUE, eval=FALSE}
asave <- phichoice_sp()
asave
```
For the `nyspatial` data example 0.4 turns out to be the optimal value for $\phi$. 


## Fitting spatial models with nugget effect

A general spatial model with nugget effect is written as: 
\begin{equation}
Y({\bf s}_i) =  {\bf x}'({\bf s}_i) \mathbf{\beta} + w({\bf s}_i) + \epsilon(
{\bf s}_i)
(\#eq:spatialwithnugget)
\end{equation}
for all $i=1, \ldots, n$. In the above equation, the pure error term $\epsilon({\bf s}_i)$ is assumed to follow the independent zero mean normal distribution
with variance $\sigma^2_{\epsilon}$, called the nugget effect, for all $i=1. \ldots, n$.  The stochastic process $w({\bf s})$ is assumed to follow a zero mean  Gaussian Process with the Matern covariance function, see @Sahubook for more details. 


The un-observed random variables $w({\bf s}_i)$, $i=1, \ldots, n$, also known as 
the spatial random effects can be integrated out to arrive at the marginal model 
\begin{align}
{\bf Y}  & \sim   N_n\left(X{\mathbf \beta}, \sigma^2_{\epsilon} \, I + \sigma^2_w 
S_w \right),   (\#eq:spatialmarginal) 
\end{align}
where the matrix $S_w$ is determined using the Matern correlation function. 
This marginal model is fitted using any of the three packages mentioned above. 
The code for this model fitting is very similar to the one for fitting `M2` above; the only 
important change is in the `package=` argument as noted below. 
```{r}
M3 <- Bspatial(package="spBayes", formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, 
               coordtype="utm", coords=4:5, prior.phi=c(0.005, 2), mchoice=T)
M4 <- Bspatial(package="stan", formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, 
               coordtype="utm", coords=4:5,phi=0.4, mchoice=T)
M5  <- Bspatial(package="inla",formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, 
               coordtype="utm", coords=4:5, mchoice=T)
```

Model fitting is very fast except for `M4` with the `stan` package. The model run 
for `M4` takes about 20 minutes on a fast personal computer. These run produces the 
following table of values of various Bayesian model choice criteria. 
<!-- \@ref(tab:lmcrit). -->
\begin{tabular}{rrrrrrr}
  \hline
 & M0 & M1 & M2 & M3 & M4 & M5 \\ 
  \hline
$p_{\mbox{DIC}}$ & 2.07 & 4.99 & 4.98 & 5.17 & 4.95 & 4.03 \\ 
 $p_{\mbox{DIC alt}}$  & 13.58 & 5.17 & 5.16 & 7.83 & 5.25 &  \\ 
  DIC  & 169.20 & 158.36 & 158.06 & 158.68 & 158.01 & 156.94 \\ 
 DIC Alt  & 192.22 & 158.72 & 158.41 & 163.99 & 158.62 &  \\ 
$p_{\mbox{waic 1}}$  & 1.82 & 5.20 & 4.93 & 4.88 & 4.50 & 4.56 \\ 
 $p_{\mbox{waic 2}}$   & 2.52 & 6.32 & 5.91 & 6.77 & 5.43 &  \\ 
  WAIC 1 & 168.95 & 158.57 & 157.51 & 158.70 & 157.11 & 158.12 \\ 
  WAIC 2   & 170.35 & 160.82 & 159.47 & 162.48 & 158.97 &  \\ 
  gof & 593.54 & 327.98 & 330.08 & 323.56 & 319.27 & 334.10 \\ 
  penalty & 575.80 & 351.52 & 346.73 & 396.63 & 397.63 & 38.92 \\ 
  PMCC & 1169.34 & 679.50 & 676.82 & 720.18 & 716.90 & 373.02 \\    \hline
\end{tabular}
```{r lmcrit, echo=FALSE}
knitr::kable(0, caption="Model choice criteria for various models.")
```
Mathematical expressions for all the quantities in the above table are 
provided in @Sahubook. Here  M0 is the intercept only model for which the results are obtained using the  following `bmstdr` command,
```{r}
Bmchoice(case="MC.sigma2.unknown", y=ydata).
```
The implementation using `inla` does not calculate the alternative values of the DIC and WAIC.

## Illustrating the model validation statistics
The model fitting function `Bspatial` also calculates the values of four validation 
statistics: 
- root mean square-error (rmse), 
- mean absolute error (mae), 
- continuous ranked probability score (crps) and
- coverage (cvg) 
if an  additional argument `validrows` containing the row numbers of the supplied 
data frame to be validated is provided. 

Data from eight validation sites 8, 11, 12, 14, 18, 21, 24 and 28 are set aside and model fitting is performed using the data from the remaining 20 sites. 

The `bmstdr` command for performing validation needs an additional argument `validrows` which are the row numbers of the supplied data frame which should be used for validation. Thus the commands for validating at the
sites 8, 11, 12, 14, 18, 21, 24, and 28   are given by: 
```{r}
s <- c(8,11,12,14,18,21,24,28)
f1 <- yo3~xmaxtemp+xwdsp+xrh
M1.v <-  Bspatial(package="none", model="lm", formula=f1, 
                  data=nyspatial, validrows=s)
M2.v <- Bspatial(package="none", model="spat", formula=f1, 
        data=nyspatial,   coordtype="utm", coords=4:5,phi=0.4,  validrows=s)
M3.v <-  Bspatial(package="spBayes", prior.phi=c(0.005, 2), formula=f1,
        data=nyspatial,   coordtype="utm", coords=4:5, validrows=s) 
M4.v  <- Bspatial(package="stan",formula=f1, 
    data=nyspatial,   coordtype="utm", coords=4:5,phi=0.4 , validrows=s) 
M5.v  <- Bspatial(package="inla", formula=f1, data=nyspatial,   
        coordtype="utm", coords=4:5, validrows=s) 
```
The table below presents the validation statistics for all five models.  Coverage
is 100\% for all five models and the validation performances are comparable. 
Model  `M2` with $\phi=0.4$ can  be used as the best model if it is imperative that
one must be  chosen.  
\begin{tabular}{rrrrrr}
  \hline
 & M1 & M2 & M3 & M4 & M5 \\ 
  \hline
  rmse & 2.447 & 2.400 & 2.428 & 2.352 & 2.374 \\ 
  mae & 2.135 & 2.015 & 2.043 & 1.946 & 1.967 \\ 
  crps & 1.508 & 1.483 & 1.495 & 1.474 & 1.473 \\ 
   \hline
\end{tabular}

To illustrate $K$-fold cross-validation, the 28 observations  in the `nyspatial` data set are randomly assigned to $K=4$ groups of equal size. 
```{r, echo=TRUE, eval=TRUE}
set.seed(44)
x <- runif(n=28)
u <- order(x)
s1 <- u[1:7]
s2 <- u[8:14]
s3 <- u[15:21]
s4 <- u[22:28]
```
Now the `M2.v` command is called four times with the `validrows` argument taking values `s1, ... s4`.  The table below  presents the 4-fold cross-validation statistics for `M2` only.  It shows a wide variability in performance
with a low coverage of 57.14\% for Fold 3. 
\begin{tabular}{rrrrr}
  \hline
  & Fold 1 & Fold 2 & Fold 3 & Fold 4 \\
  \hline
rmse & 2.441 & 5.005 & 5.865 & 2.508 \\ 
  mae & 1.789 & 3.545 & 5.462 & 2.145 \\ 
  crps & 1.462 & 2.752 & 4.194 & 1.501 \\ 
  cvg & 100\% & 85.71\% & 57.14\% & 100\% \\ 
   \hline
\end{tabular}
A validation plot is automatically drawn each time a validation is performed. Below, we include the validation plot for fold-3 only. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M2.v3 <- Bspatial(model="spat", formula=yo3~xmaxtemp+xwdsp+xrh, data=nyspatial, 
               coordtype="utm", coords=4:5, validrows= s3, phi=0.4, verbose = FALSE)
```
In this particular instance four of the seven validation observations are over-predicted. The above figure shows low coverage and high rmse. However, these statistics  are  based on data from seven validation sites only and as a result these may have large variability explaining the differences in the $K$-fold validation
results. 

The above validation plot has been drawn using the `bmstdr` command `obs_v_pred_plot`. This validation plot may be drawn without the line segments, which is recommended when there are a large number of validation observations. The plot may also use the `mean` values of the predictions instead of the default `median` values. The documentation 
of the function explains how to do this. For example, having the fitted object `v3`, we may issue the command: 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
names(M2.v3)
psums <- get_validation_summaries(M2.v3$valpreds)
names(psums)
obs_v_pred_plot(yobs=M2.v3$yobs_preds$yo3, predsums=psums, segments=F, summarystat = "mean" )
```



# Point reference spatio-temporal data modeling

## Illustration data set nysptime

To illustrate point reference spatio-temporal data modeling we use the `nysptime` data set included in the package. This is a spatio-temporal version of the data set `nyspatial` introduced in Section \@ref(illustration-data-set-nyspatial).  This data set, taken from @sahu_bakar_stamet,  has 1736 rows and 12 columns containing ground level ozone air pollution data from 28 sites in the state of New York for the 62 days in July and August 2006. 
For regression modeling purposes, the response variable is `y8hrmax` and the three important covariates are maximum temperature: `xmaxtemp` in degree Celsius, wind speed: `xwdsp` in nautical miles and  percentage average relative humidity: `xrh`. 

## The Bsptime function for fitting spatio-temporal models
In this section we extend the spatial model \@ref(eq:spatialwithnugget) to the following spatio-temporal model. 
\begin{equation}
Y({\bf s}_i, t) =  {\bf x}'({\bf s}_i, t) \mathbf{\beta} + w({\bf s}_i, t) + \epsilon(
{\bf s}_i, t)
(\#eq:spatiotemporalwithnugget)
\end{equation}
for $i=1, \ldots, n$ and $t=1, \ldots, T.$ Different distribution specifications for  the spatio-temporal  random effects $w({\bf s}_i, t)$ and the observational errors 
$\epsilon({\bf s}_i, t)$ give rise to different models. Variations of these models have been described in @Sahubook.  The `bmstdr` function `Bsptime` has been developed to fit these models. 

Similar to the `Bspatial` function, the `Bsptime` function takes a formula and a data argument. It is important to note that the `Bsptime` function *always assumes* that the data frame is first sorted by space and then time within each site in space. Note that missing covariate values  are not permitted at all.

The arguments defining the scale, `scale.transform`, 
and the hyper parameters of the prior distribution for the regression coefficients ${\mathbf \beta}$ and the variance parameters are also similar to the corresponding ones in the spatial model fitting case with `Bspatial`. Other important arguments 
are described below. 

The arguments `coordtype`, `coords`, and `validrows` are also similarly defined as before. However, note that when the separable  model is fitted the `validrows` argument must include all the rows of time points  for each site to be validated. 

The `package` argument can take one of six values: `spBayes`, `stan`, `inla`, `spTimer`, `sptDyn` and `none` with `none` being the default. Fittings using each of these package options  are illustrated in the sections below. 
Only a limited number 
of models, specified by the `model` argument,  can be fitted with each of these six choices.  The `model` argument is described below. 

 In case the package is `none`, the `model` can either be 
`lm` or `seperable`. The `lm` option is for an independent error regression model while the other option fits a separable spatio-temporal model without any nugget effect. The separable model fitting method cannot handle missing data. All missing data points in the response variable will be replaced by the grand mean of the available observations. When the `package` option is one of the five 
named packages the `model` argument is passed to the chosen package. 

For fitting a `separable` model `Bsptime` requires specification of
two decay parameters $\phi_s$ and $\phi_t$. If these are not specified then values are chosen which correspond to the effective ranges  as the maximum distance in space and and length in time.

There are numerous other package specific arguments that define the prior distributions and many important behavioral aspects of the selected package. Those are not described here. Instead the user is directed to the documentation `?Bsptime` and also the vignettes of the individual packages. 


With the default value of `package="none"` the independent error regression model `M1` and the separable model `M2` are fitted using the commands: 
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
f2 <- y8hrmax~xmaxtemp+xwdsp+xrh
M1 <- Bsptime(model="lm", formula=f2, data=nysptime, scale.transform = "SQRT", N=5000)
M2 <- Bsptime(model="separable", formula=f2, data=nysptime, scale.transform = "SQRT",
              coordtype="utm", coords=4:5,  N=5000)
```
The fitted model objects `M1` and `M2` are of class `bmstdr` and these can be explored using the S3 methods `print, plot`, `summary` and `residuals`. 
To explore the model fitted object issue the command `names(M2)`.  Here we explore the residuals by issuing the command: 
```{r, echo=TRUE, eval=TRUE}
a <- residuals(M2)
```
This command renders a multiple time series plot of the residuals.  
However, the same command `a <- residuals(M1)` will not draw the residual plot since the independent error regression model is not aware of the temporal structure of the data. In this case it is possible to modify the command to 
```{r, echo=TRUE, eval=TRUE}
a <- residuals(M1, numbers=list(sn=28, tn=62))
```
to have the desired result, see `?residuals.bmstdr`. 

## Exploring the separable model 

The above command for fitting `M2` does not specify the values of the  spatial and temporal decay parameters $\phi_s$ and $\phi_t$. The adopted values of these parameters are printed by the command: 
```{r, echo=TRUE, eval=FALSE}
M2$phi.s; M2$phi.t
```
These values are approximately 0.005 and 0.048 which  correspond to the spatial range (the value of distance by which spatial correlation dies down) of 591 kilometers and the temporal range of 62 days which are the maximum possible values for the spatial and temporal domains of the data. 

Optimal values of  $\phi_s$ and $\phi_t$ can be determined by performing a grid search as in the case spatial only model fitting with `Bspatial`. The `bmstdr` package contains a function called `phichoice` which does this grid search specifically for the `nysptime` data set using the eight validation sites noted 
earlier. The command is `asave <- phichoicep()`.  The optimal values in this case turns out to be $\phi_s=0.005$ and $\phi_t=0.05$. 


We now explore model validation for the separable model using the eight sites chosen previously.
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
valids <-  c(8,11,12,14,18,21,24,28)
vrows <-  which(nysptime$s.index%in% valids)
M2.1 <- Bsptime(model="separable",  formula=f2, data=nysptime, 
             validrows=vrows, coordtype="utm", coords=4:5,
             phi.s=0.005, phi.t=0.05, scale.transform = "SQRT")
```
```{r, echo=TRUE, eval=TRUE, message=FALSE}
summary(M2.1)
```
The fitted model `M2.1` can be passed to the `plot` function that may draw 
several plots depending on the contents of the model fitted object. For example, this always draws a residuals against fitted values plot. The `plot` command for objects of class `bmstdr` can take  additional arguments such as `segments = F` 
which will provide a  plot of the predicted values against observations without the line segments. 

## Spatio-temporal model fitting with the spTimer package
The `spTimer` package @spTimer can be used to fit, predict and forecast using various spatio-temporal models. This package also offers a great deal of flexibility in data modeling since it can model segmented time series data and also mixture of discrete and continuous data such as precipitation. The `bmstdr` function `Bsptime` can implement these models by invoking the  `package="spTimer"` option. 
For example,  
```{r, echo=T, eval=T,message=FALSE, results='hide' }
M3 <- Bsptime(package="spTimer", formula=f2, data=nysptime, 
              coordtype="utm", coords=4:5, scale.transform = "SQRT", 
              N=5000)
```
As before,  the fitted model object `M3` can be explored using the `print, summary, plot` and `residuals` commands. The `plot` command will draw the MCMC trace and density plots for each model parameter.  The output plots of these commands are omitted from this document for brevity. Instead, we show validation performance at three selected sites: 1, 5, and 10 as shown in the map. 
```{r, echo=FALSE, eval=TRUE}
nymap <- map_data(database="state",regions="new york")
s <- c(1, 5, 10)
fcoords <- nyspatial[-s, c("Longitude", "Latitude")]
vcoords <- nyspatial[s,  c("Longitude", "Latitude")]
library(tidyr)
label <- tibble(
   long = -76.1,
   lat = 41.5,
   label = "25 fitted (circles) & 3  \n  validation (numbered) sites"
)

vsites3 <- ggplot() +
   geom_polygon(data=nymap, aes(x=long, y=lat, group=group),
                color="black", size = 0.6, fill=NA) +
   geom_point(data =fcoords, aes(x=Longitude,y=Latitude)) +
   geom_text(data=vcoords, aes(x=Longitude,y=Latitude, label=s), col=4) +
   labs( title= "28 air pollution monitoring sites in New York", x="Longitude", y = "Latitude") +
   geom_text(aes(label=label, x=long, y=lat), data = label, vjust = "top", hjust = "right")  +
   # geom_rect(mapping=aes(xmin=-80.2, xmax=-77.3, ymin=41, ymax=41.6), color="black", fill=NA) + 
   geom_rect(mapping=aes(xmin=-78.7, xmax=-75.8, ymin=41, ymax=41.6), color="black", fill=NA) + 
   ggsn::scalebar(data =nymap, dist = 100, location = "bottomleft", transform=T, dist_unit = "km",
                  st.dist = .05, st.size = 5, height = .06, st.bottom=T, model="WGS84") +
   ggsn::north(data=nymap, location="topleft", symbol=12) 
vsites3
```
We randomly select 31 time points for validation at the three selected sites and identify the validation rows by using the following commands. 
```{r, echo=T, eval=T}
set.seed(44)
tn <- 62
sn <- 28
valids <- c(1, 5, 10)
validt <- sort(sample(1:tn, size=31))
vrows <- getvalidrows(sn=sn, tn=tn, valids=valids, validt=validt)
```
The `getvalidrows` command is included in the `databmstdr` library. Now we use the 
`spTimer` package to fit and validate the model. 
```{r, echo=T, eval=T, message=FALSE, results='hide', fig.show='hide'}
M31 <- Bsptime(package="spTimer",formula=f2, data=nysptime, 
               coordtype="utm", coords=4:5,
               validrows=vrows, model="GP", 
               mchoice=F, scale.transform = "NONE", N=5000)
```
For ease of illustration we have chosen `scale.transform = "NONE"`. More complicated  additional coding will be required if a different scale is chosen. 

We illustrate a plot of the observations, fitted values and the validation predictions and their uncertainty intervals as plotted in Figure 11.13 in the book @banerjeebook2015. 
The `databmstdr` package includes the function `fig11.13.plot` to generate this plot.
The arguments required for this function are prepared as follows. The `spTimer` package does not provide the 95\% intervals for the fitted values nor does it provide the MCMC samples of the fitted values which can be used to construct the 95\% intervals. Hence, in the code below we use a normal approximation to obtain the uncertainty intervals. 
Now we first organize the data for plotting. 
```{r, echo=T, eval=T}
modfit <- M31$fit
fitall <- data.frame(modfit$fitted)
fitall$s.index <- rep(1:sn, each=tn)
library(spTimer)
vdat <- spT.subset(data=nysptime, var.name=c("s.index"), s=valids)
fitvalid <- spT.subset(data=fitall, var.name=c("s.index"), s=valids)
fitvalid$low <- fitvalid$Mean - 1.96 * fitvalid$SD
fitvalid$up <- fitvalid$Mean + 1.96 * fitvalid$SD
fitvalid$yobs <- vdat$y8hrmax
yobs <- matrix(fitvalid$yobs, byrow=T, ncol=tn)
y.valids.low <- matrix(fitvalid$low, byrow=T, ncol=tn)
y.valids.med <- matrix(fitvalid$Mean, byrow=T, ncol=tn)
y.valids.up <- matrix(fitvalid$up, byrow=T, ncol=tn)
```
Now we call the `fig11.13.plot` function to render the plot for each site.
```{r, echo=T, eval=T}
p1 <- fig11.13.plot(yobs[1, ], y.valids.low[1, ], y.valids.med[1, ], 
                    y.valids.up[1, ], misst=validt)
p1 <- p1 + ggtitle("Validation for Site 1")
p2 <- fig11.13.plot(yobs[2, ], y.valids.low[2, ], y.valids.med[2, ], 
                    y.valids.up[2, ], misst=validt)
p2 <- p2 + ggtitle("Validation for Site 5")
p3 <- fig11.13.plot(yobs[3, ], y.valids.low[3, ], y.valids.med[3, ], 
                    y.valids.up[3, ], misst=validt)
p3 <- p3 + ggtitle("Validation for Site 10")
library(ggpubr)
ggarrange(p1, p2, p3, common.legend = TRUE, legend = "top", nrow = 3, ncol = 1)
```

This ability to fit and validate using user defined validation rows is an enhancement of the `spTimer` package since that only allows validation at all time points for any selected site. The original package does not allow selective predictions at a subset of time points. 


#### Illustrating spatio-temporal predictions

The `spTimer` package includes a prediction method function that can be used to predict at a large number locations. It does these predictions at all time points of the modeling data hence the covariates used in the model must be available for all prediction locations and at all time points. We illustrate  the predictions using the fitted model `M3`. We only show the average predicted pollution map over the 62 days. 
To do the site-wise averaging we use the `sitemeans` function: 
```{r, echo=T, eval=T}
sitemeans <- function(a, sn, tn=62) { 
   u <- matrix(a, nrow=sn, ncol=tn, byrow=T)
   b <- apply(u, 1, mean)
   as.vector(b)
}
```

The `bmstdr` package includes the data set `gridnysptime` which contains the prediction data for 100 locations within the state of New York. Here is the 
code-chunk to perform prediction  at these 100 locations and then averaging: 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
post <- M3$fit
gpred <- predict(post, newdata=gridnysptime, newcoords=~Longitude+Latitude)
u <- gpred$pred.samples
v <- apply(u, 2, sitemeans, sn=100)
a <- get_parameter_estimates(t(v)) 
b <- data.frame(gridnyspatial[, 1:5], a) 
```
The data frame `b` contains the location information and the prediction summaries at the 100 prediction sites. To draw the prediction map we also include the fitted values from the 28 data modeling sites. We extract the fitted values as follows:  

```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
meanmat <- post$op
sig2eps <-  post$sig2ep
sige <- sqrt(sig2eps)
itmax <- ncol(meanmat)
nT <- nrow(nysptime)
sigemat <- matrix(rep(sige, each=nT), byrow=F, ncol=itmax)
a <- matrix(rnorm(nT*itmax), nrow=nT, ncol=itmax)
ypreds <- meanmat + a * sigemat
ypreds <-  (ypreds)^2
v <- apply(ypreds, 2, sitemeans, sn=28)
a <- get_parameter_estimates(t(v)) 
fits <- data.frame(nyspatial[, 1:5], a)
```
Finally we combine the predictions and the fitted values by the command: 
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
b <- rbind(b, fits)
```
Now we can obtain the average pollution map by using the linear interpolation function
`interp` in the `akima` library. Also we discard the interpolations outside the state of New York by using the function `fnc.delete.map.XYZ` provided by the `databmstdr` package. 



```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
coord <- nyspatial[, c("Longitude","Latitude")]
library(akima)
xo <- seq(from=min(coord$Longitude)-0.5, to = max(coord$Longitude)+0.8, length=200)
yo <- seq(from=min(coord$Latitude)-0.25, to = max(coord$Latitude)+0.8, length=200)
surf <- interp(b$Longitude, b$Latitude, b$mean,  xo=xo, yo=yo)
v <- fnc.delete.map.XYZ(xyz=surf)

interp1 <- data.frame(long = v$x, v$z )
names(interp1)[1:length(v$y)+1] <- v$y
library(tidyr)
interp1 <- gather(interp1,key = lat,value =Predicted,-long,convert = TRUE)
library(ggplot2)
nymap <- map_data(database="state",regions="new york")
mappath <- cbind(nymap$long, nymap$lat)
zr <- range(interp1$Predicted, na.rm=T)
P <- ggplot() +  
geom_raster(data=interp1, aes(x = long, y = lat,fill = Predicted)) +
geom_polygon(data=nymap, aes(x=long, y=lat, group=group), color="black", size = 0.6, fill=NA) + 
geom_point(data=coord, aes(x=Longitude,y=Latitude))  +
stat_contour(data=na.omit(interp1), aes(x = long, y = lat,z = Predicted), colour = "black", binwidth =2) +
scale_fill_gradientn(colours=colpalette, na.value="gray95", limits=zr) +
theme(axis.text = element_blank(), axis.ticks = element_blank()) +
ggsn::scalebar(data =interp1, dist = 100, location = "bottomleft", transform=T, dist_unit = "km", st.dist = .05, st.size = 5, height = .06, st.bottom=T, model="WGS84") +
ggsn::north(data=interp1, location="topleft", symbol=12) +
labs(x="Longitude", y = "Latitude", size=2.5) 
```
Similar methods are used to obtain a map of the standard deviations of the predictions saved as a `ggplot` object `Psd`.   
```{r, echo=FALSE, eval=TRUE, message=FALSE, results='hide'}
surf <- interp(b$Longitude, b$Latitude, b$sd,  xo=xo, yo=yo)
v <- fnc.delete.map.XYZ(xyz=surf)
interp1 <- data.frame(long = v$x, v$z )
names(interp1)[1:length(v$y)+1] <- v$y
interp1 <- gather(interp1,key = lat,value =sd,-long,convert = TRUE)
nymap <- map_data(database="state",regions="new york")
mappath <- cbind(nymap$long, nymap$lat)
zr <- range(interp1$sd, na.rm=T)
Psd <- ggplot() +  
   geom_raster(data=interp1, aes(x = long, y = lat,fill = sd)) +
   geom_polygon(data=nymap, aes(x=long, y=lat, group=group), color="black", size = 0.6, fill=NA) + 
   geom_point(data=coord, aes(x=Longitude,y=Latitude))  +
   stat_contour(data=na.omit(interp1), aes(x = long, y = lat,z = sd), colour = "black", binwidth =0.1) +  
   scale_fill_gradientn(colours=colpalette, na.value="gray95", limits=zr) +
   theme(axis.text = element_blank(), axis.ticks = element_blank()) +
   ggsn::scalebar(data =interp1, dist = 100, location = "bottomleft", transform=T, dist_unit = "km",
                  st.dist = .05, st.size = 5, height = .06, st.bottom=T, model="WGS84") +
   ggsn::north(data=interp1, location="topleft", symbol=12) +
   labs(x="Longitude", y = "Latitude", size=2.5) 
```
The maps are provided in the two figures below. 
```{r, echo=F, eval=T, fig.height=6, fig.width=8, fig.cap="Predicted map of average ozone air pollution in New York"}
P
```
```{r, echo=F, eval=T, fig.height=6, fig.width=8, fig.cap="Sd map of predicted air pollution in New York"}
Psd
```


## Marginal model fitting with the rstan package
The option `package="stan"` can be used to fit the only available model, which is a marginalized GP model, like  \@ref{eq:spatialmarginal} independently at each time point. Details for this model are provided in Chapter 7 of the book @Sahubook. In this implementation the spatial decay parameter $\phi$ is sampled and its estimate is made available in the parameter estimates table. 

We illustrate model fitting by comparing the `stan` fitted model with the three previously fitted models. The commands for fitting all four models are: 
```{r, echo=TRUE, eval=FALSE, tidy=TRUE}
M1.c <- Bsptime(model="lm", formula=f2, data=nysptime, 
          scale.transform = "SQRT", mchoice=T)
M2.c <- Bsptime(model="separable",  formula=f2, data=nysptime, 
          coordtype="utm", coords=4:5, phi.s=0.005, phi.t=0.05, 
          scale.transform = "SQRT", mchoice=T)
M3.c <- Bsptime(package="spTimer", model="GP", 
        formula=f2, data=nysptime, coordtype="utm", 
        coords=4:5, scale.transform = "SQRT", 
        mchoice=T, N=5000)
M4.c <- Bsptime(package="stan",formula=f2, data=nysptime, 
        coordtype="utm", coords=4:5, scale.transform = "SQRT", 
        N=1500, burn.in=500, mchoice=T, verbose = F)
```
The above commands have been executed to produce 
the following table of model choice criteria for the four models M1 to M4. 
\begin{tabular}{rrrrr}
  \hline
 & M1 & M2 & M3 & M4\\ 
  \hline 
$p_{\mbox{DIC}}$ & 5.06 & 5.07 & 78.65 & 29.96 \\ 
$p_{\mbox{DIC alt}}$  & 5.38 & 5.38 & 841.96 & 26.21 \\ 
   DIC   & 3912.25 & 3214.02 & 3132.10 & 2694.35 \\ 
 DIC alt  & 3912.88 & 3214.64 & 4658.72 & 2686.85 \\ 
  $p_{\mbox{waic 1}}$  & 4.95 & 14.11 & 48.53 & 9.27 \\ 
  $p_{\mbox{waic 2}}$ & 4.97 & 14.18 & 132.90 & 10.14 \\ 
 WAIC 1  & 3912.14 & 2449.15 & 2603.86 & 2089.15 \\ 
 WAIC 2 & 3912.18 & 2449.30 & 2772.60 & 2090.89 \\ 
  gof & 963.68 & 286.21 & 216.75 & 328.93 \\ 
  penalty & 967.10 & 240.63 & 873.84 & 362.23 \\ 
  PMCC & 1930.78 & 526.85 & 1090.59 & 691.16 \\ 
   \hline
\end{tabular}

To see how these models perform we refit the models by requesting to validate. The validation rows are selected by issuing the commands: 
```{r}
valids <- c(8,11,12,14,18,21,24,28)
vrows <- getvalidrows(sn=28, tn=62, valids=valids, allt=T)
```
The four commands to fit `M1.c` to `M4.c` are modified to include the option 
`validrows=vrows` and setting `mchoice=FALSE` to speed up computations. Execution of the four modified commands produces the table: 
\begin{tabular}{rrrrr}
  \hline
 & M1 & M2 & M3 & M4 \\ \hline 
rmse & 9.37 & 6.50 & 6.40 & 6.41 \\ 
  mae & 7.55 & 5.01 & 4.94 & 4.84 \\ 
  crps & 5.25 & 5.75 & 4.07 & 3.54 \\ 
  cvg & 97.95 & 99.59 & 99.59 & 92.83 \\ 
\hline
\end{tabular}

## Autoregressive model fitting with spTimer and INLA 

Temporal auto regressive (AR) models can be fitted using both the `spTimer` and `INLA` package. The command for fitting the AR model using the `spTimer` package requires 
the additional option `model="AR"`: 
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
M5 <- Bsptime(package="spTimer", model="AR", formula=f2, data=nysptime, 
                coordtype="utm", coords=4:5, scale.transform = "SQRT", 
                mchoice=T,  N=5000, validrows = vrows)

```
The residual plot provided below shows much less autocorrelation than the similar plot shown earlier for model `M1`.  
```{r, echo=TRUE, eval=TRUE, results='hide'}
a <- residuals(M5)
```
To fit and validate with the AR model using the INLA package we issue the command: 
```{r, echo=TRUE, eval=FALSE, message=FALSE, results='hide'}
M6 <- Bsptime(package="inla", model="AR", formula=f2, data=nysptime, 
        coordtype="utm", coords=4:5, scale.transform = "SQRT", 
        mchoice=T, validrows=vrows)
```
The AR models `M5` and `M6` are used to obtain the following results. 
\begin{tabular}{rrrrrrrr}
  \hline
Package  & gof & penalty & PMCC & rmse & mae & crps & cvg \\ 
  \hline
spTimer & 321.33 & 607.31 & 928.64 & 6.46 & 4.99 & 3.87 & 99.39 \\ 
 INLA & 718.85 & 20.97 & 739.82 & 9.43 & 7.51 & 5.80 & 62.70 \\ 
   \hline
\end{tabular}
Here validation has been performed using all the 62 temporal observations from the eight validation sites noted before. Our implementation of `M6` using INLA seems to suffer from low coverage values, although the other three model validation statistics values are quite comparable. 


## Spatio-temporal dynamic models using the spTDyn package 

The `spTDyn` package can be used to fit dynamic models in both time and space. A spatial dynamic model allows the regression coefficient to vary in space. A temporal dynamic model allows the regression coefficient to have a dynamic equation in time. To invoke these dynamic models the regression variables are specified in the 
formula argument with the optional enclosures `sp` for spatially dynamic and `tp` for temporally dynamic. Here is an example where the model is specified to have spatially varying effects of maximum temperature and dynamic regression coefficients for 
wind speed. 
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
library(spTDyn)
f3 <- y8hrmax~ xmaxtemp + sp(xmaxtemp)+ tp(xwdsp) + xrh
M7 <- Bsptime(package="sptDyn", model="GP", formula=f3, data=nysptime, 
      coordtype="utm", coords=4:5, scale.transform = "SQRT", 
      mchoice=T,  N=5000, n.report=2)
```
The model fitting results can be examined by the S3 methods functions as before. Here we explore the spatially varying regression coefficients as follows:
```{r echo=TRUE, eval=TRUE, message=FALSE, tidy=TRUE}
out <- M7$fit
dim(out$betasp)
a <- out$betasp
u <- c(t(out$betasp))
sn <- nrow(a)
itmax <- ncol(a)
v <- rep(1:sn, each=itmax)
d <- data.frame(site=as.factor(v), sp = u)
p <- ggplot(data=d, aes(x=site, y=sp)) + 
   geom_boxplot(outlier.colour="black", outlier.shape=1,
                outlier.size=0.5) +
   geom_abline(intercept=0, slope=0, color="blue") + 
   labs(title= "Spatial effects of maximum temperature", x="Site", y = "Effects", size=2.5) 
p 
```
Similarly, we provide a plot of the temporal effects parameter. 
```{r echo=TRUE, eval=TRUE, message=FALSE, tidy=TRUE}
b <- out$betatp
tn <- nrow(b)
itmax <- ncol(b)
tids <- 1:tn 
stat <- apply(b[tids,], 1, quantile, prob=c(0.025,0.5,0.975))
tstat <- data.frame(tids, t(stat))
dimnames(tstat)[[2]] <- c("Days", "low", "median", "up")
# head(tstat)
yr <- c(min(c(stat)),max(c(stat)))
p <- ggplot(data=tstat, aes(x=Days, y=median)) + 
   geom_point(size=3) + 
   ylim(yr) + 
   geom_segment(data=tstat, aes(x=Days, y=median, xend=Days, yend=low), linetype=1) +
   geom_segment(data=tstat, aes(x=Days, y=median, xend=Days, yend=up), linetype=1) +
   geom_abline(intercept=0, slope=0, col="blue") +
   labs(title="Temporal effects of wind speed", x="Days", y="Temporal effects") 
p 
```
## Fitting dynamic models using spBayes 
The package option `package="spBayes"' in the `Bsptime` function triggers model fitting by using a  complex dynamic model due to @gelfand2005, see also 
Chapter 11 of the book @banerjeebook2015. This model fitting is sensitive to the choice of the prior distributions and the options below leads to a reasonable model fit.  
```{r echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
M8 <- Bsptime(package="spBayes",  formula=f2, data=nysptime, 
              prior.sigma2=c(2, 25),
              prior.tau2 =c(2, 25),
              prior.sigma.eta =c(2, 0.001),
              coordtype="utm", 
              coords=4:5, scale.transform = "SQRT", 
              mchoice=T,  N=5000,  n.report=200)
```
The dynamic model parameters are extracted using the code below. 
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
modfit <- M8$fit
N <- 5000
burn.in <- 1000
tn <- 62
quant95 <- function(x){
   quantile(x, prob=c(0.025, 0.5, 0.975))
}
beta <- apply(modfit$p.beta.samples[burn.in:N,], 2, quant95)
theta <- apply(modfit$p.theta.samples[burn.in:N,], 2, quant95)
sigma.sq <- theta[,grep("sigma.sq", colnames(theta))]
tau.sq <- theta[,grep("tau.sq", colnames(theta))]
phi <- theta[,grep("phi", colnames(theta))]
```
These extracted parameters are plotted using the `ggplot` function. The details are omitted from this document. 

```{r, echo=FALSE, eval=TRUE, message=FALSE, results='hide'}
adat <- data.frame(x=1:tn, low=sigma.sq[1, ], med=sigma.sq[2, ], up=sigma.sq[3, ])
# head(adat)

psigma <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   theme(legend.position ="none") + 
   labs(y = "sigma2", x = "Days") 
# psigma

adat <- data.frame(x=1:tn, low=tau.sq[1, ], med=tau.sq[2, ], up=tau.sq[3, ])
# head(adat)

ptau <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   theme(legend.position ="none") + 
   labs(y = "tau2", x = "Days") 
# ptau

adat <- data.frame(x=1:tn, low=3/phi[3, ], med=3/phi[2, ], up=3/phi[1, ])
# head(adat)

prange <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   theme(legend.position ="none") + 
   labs(y = "Range", x = "Days") 
# prange
```

```{r, echo=FALSE, eval=TRUE}
ggarrange(psigma, ptau, prange, common.legend = TRUE, legend = "none", nrow = 3, ncol = 1)

```

```{r, echo=FALSE, eval=TRUE}
vnames <- all.vars(f2)
xnames <- vnames[-1]
k <- 4
# cat("\nOnly first 4 beta parameters are plotted\n")
beta.0 <- beta[,grep("Intercept", colnames(beta))]
adat <- data.frame(x=1:tn, low=beta.0[1,], med=beta.0[2,], up=beta.0[3,])
# head(adat)
pint <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   geom_hline(yintercept=0, linetype="dashed", color = "red", size=1)+
   theme(legend.position ="none") + 
   labs(y = "Intercept", x = "Days") 
# pint
j <- 2
betaj <- beta[,grep(xnames[j-1], colnames(beta))]
adat <- data.frame(x=1:tn, low=betaj[1,], med=betaj[2,], up=betaj[3,])
ptmp <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   geom_hline(yintercept=0, linetype="dashed", color = "red", size=1)+
   theme(legend.position ="none") + 
   labs(y = "Max temp", x = "Days") 
# ptmp
j <- 3
betaj <- beta[,grep(xnames[j-1], colnames(beta))]
adat <- data.frame(x=1:tn, low=betaj[1,], med=betaj[2,], up=betaj[3,])
# head(adat)
pwdsp <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   theme(legend.position ="none") +  
   geom_hline(yintercept=0, linetype="dashed", color = "red", size=1) +
   labs(y = "Wind speed", x = "Days") 
# pwdsp
j <- 4
betaj <- beta[,grep(xnames[j-1], colnames(beta))]
adat <- data.frame(x=1:tn, low=betaj[1,], med=betaj[2,], up=betaj[3,])
# head(adat)
prh <- ggplot() + 
   geom_point(data = adat, aes(x =x, y = med, shape=19), shape=19, col="blue", size = 2) + 
   geom_ribbon(data = adat, aes(x =x, ymin =low, ymax = up), alpha = 0.2, color = "grey50") +
   theme(legend.position ="none") +  
   geom_hline(yintercept=0, linetype="dashed", color = "red", size=1)+
   labs(y = "Rel humidity", x = "Days") 
# prh

```

```{r, echo=FALSE, eval=TRUE}
library(ggpubr)
ggarrange(pint, ptmp, pwdsp, prh, common.legend = TRUE, legend = "none", nrow = 2, ncol = 2)

```

## Autoregressive modeling using Gaussian predictive processes 
This is a spatio-temporal model proposed by @sahubakarasmbi. This model is suitable for modeling temporal data from a large number of spatial locations. In addition to the fixed effects regression coefficients this model sets up random effects which are temporally autoregreesive but spatially based at a much smaller 
number of locations called the knots. These knots can be specified by a `knots.coords` argument in `spTimer`. In `bmstdr` the knots may also be specified by a `g_size` argument which may define a square or a rectangular equi-spaced grid covering the 
range of coordinates of the data locations. 

The `bmstdr` command to fit a  model with a square $5 \times 5$ grid of knot locations is given by:    
```{r, echo=TRUE, eval=TRUE, message=FALSE, results='hide'}
M9 <-  Bsptime(package="spTimer", model="GPP", g_size=5, 
               formula=f2, data=nysptime, 
               coordtype="utm", coords=4:5, scale.transform = "SQRT")
```
The grid size parameter `g_size` can be chosen by cross-validation methods as has been demonstrated in @Sahubook. The model fitted object `M9` can be examined using the suite of S3 functions as before.  

## Comparing all the spatio-temporal models 
The `bmstdr` package function can be used compare all the model fits and the performance of the models as evaluated by the four validation statistics. 
We set aside all the data from the eight sites as noted previously. 
This gives us 496 ($=8 \times 62$) data points the validation set and the model is fitted with remaining 1240 space time observations from the 20 modeling sites.
The table below reports the results. 
\begin{tabular}{rrrrrrrrr}
  \hline
  & M1 & M2 & M3 & M4 & M5 & M6 & M7 & M9 \\ 
  \hline
rmse & 9.35 & 6.46 & 6.40 & 6.41 & 9.43 & 6.46 & 6.59 & 6.36 \\ 
  mae & 7.54 & 4.98 & 4.94 & 4.84 & 7.52 & 4.99 & 5.11 & 4.85 \\ 
  crps & 5.24 & 5.74 & 4.07 & 3.55 & 5.80 & 3.87 & 3.79 & 4.16 \\ 
  cvg & 98.16 & 99.59 & 99.59 & 92.01 & 64.14 & 99.39 & 99.39 & 99.39 \\ 
  G & 728.91 & 218.36 & 181.71 & 173.46 & 516.16 & 185.76 & 71.30 & 146.69 \\ 
  P & 731.61 & 195.18 & 935.42 & 266.10 & 16.89 & 718.47 & 467.46 & 815.85 \\ 
  $G+P$ & 1460.52 & 413.54 & 1117.13 & 439.56 & 533.05 & 904.23 & 538.76 & 962.54 \\ 
   \hline
\end{tabular}
In the above table we have omitted M8, the model based on `spBayes` because we were not able to produce comparable results. We do not report the
WAIC and the DIC since those are not available in the `bmstdr` package for all the models. @Sahubook provides further discussion of the results. 
  

We end this comparison with some words of caution.  The comparison should not be generalized to make statements like package A
performs better  than package B. For example, the marginal GP model, M4, implemented using `stan` performed slightly worse than M9. But there may
be another model, e.g. auto-regressive,  implemented using `stan`,  that may perform better than the `spTimer` models.  The worth of this illustration lies in the comparison itself. Using the `bmstdr` package it is straightforward to compare different models implemented in different packages without having to learn and program the individual packages. 


# Modeling areal unit data 

In contrast to point reference spatial and spatio-temporal data areal unit data  
refers to a collection of observations  whose spatial references are given by adjacent areas on a map. For example, the next section discusses two data sets on providing the number of  deaths due to Covid-19 in 313 local administrative areas in England.  Areal unit data can often be either discrete, e.g. number of 
deaths, or continuous e.g. average air pollution level in a city. Hence we proceed to model such data sets using the generalized linear models (GLM) [@McCullaghNelder1989]. 
Chapter 10 of the  book by @Sahubook also provides a gentle introduction to  GLM. 
This chapter also discusses spatial and spatio-temporal models based on GLMs. In the remainder of this section we illustrate model fitting and model comparison  for these models. 


## Two illustration data sets on Covid-19 mortality from England

The `engtotals` data set  presents the number of deaths due to Covid-19 during the  peak from March 13 to July 31, 2020 in the 313 Local Authority Districts, Counties  and Unitary Authorities (LADCUA)  in England.

```{r, echo=T, eval=T, fig.cap="Covid death rate per 100,000 during Mar 13 to Jul 31, 2020"}
bdf <- merge(englamap, engtotals, by.x="id", by.y="mapid", all.y=T, all.x=F)
bdf$covidrate <- bdf$covid/bdf$popn*100000
plimits <- range(bdf$covidrate)
prate <-  ggplot(data=bdf, aes(x=long, y=lat, group = group, fill=covidrate)) +
  scale_fill_gradientn(colours=colpalette, na.value="black",limits=plimits)  +
  geom_polygon(colour='black',size=0.25) +
  geom_polygon(data=engregmap, aes(x=long, y=lat, group = group), fill=NA, colour='black',size=0.6)  +
  coord_equal() + guides(fill=guide_colorbar(title="Death rate")) +
  theme_bw()+theme(text=element_text(family="Times")) +
  labs(x="", y = "") +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank(),axis.ticks = element_blank())   +
  theme(legend.position =c(0.2, 0.5)) +
  ggsn::scalebar(data=bdf, dist =50, location = "topleft", transform=F, dist_unit = "km",
                 st.dist = .05, st.size =4, height = .06, st.bottom=T)
prate
```

The `engdeaths` data set contains 49,292 weekly recorded deaths during this period of 20 weeks. 
The boxplot of the weekly death rates  shows the first peak during weeks 15 and 16
(April 10th to 23rd) and a very slow decline of the death numbers after the peak. The main purpose here is to model
the spatio-temporal variation in the death rates. 
```{r, echo=T, eval=T}
engdeaths$covidrate <- 100000*engdeaths$covid/engdeaths$popn
ptime <- ggplot(data=engdeaths,  aes(x=factor(Weeknumber), y=covidrate)) +
  geom_boxplot() +
  labs(x = "Week", y = "Death rate per 100,000")  +
  stat_summary(fun=median, geom="line", aes(group=1, col="red")) +
  theme(legend.position = "none")
ptime
```


## The Bcartime function for fitting CAR models

The `bmstdr` package function `Bcartime` fits a variety of spatial and spatio-temporal models for areal data. These models are based on the generalized linear models with one of binomial, Poisson and Gaussian error distributions and with the canonical link in each case.  Chapter 10 of the book by @Sahubook describe the models. The fitted output can be explored using the S3 methods functions as in the case of `Bspatial` and `Bsptime` for modeling point reference spatial data. More details are provided below. 

To fit the Bayesian GLMs without any random effects
 `Bcartime` employs the `S.glm` function of the `r CRANpkg("CARBayes")` package @LeeCARBayes2021.  Deploying the `Bcartime` function requires the following essential arguments:
 
 - `package` can take one of three possible values:  `"CARBayes"`, `"CARBayesST"` or 
 `"inla"`. The default is  `"CARBayes"`. 
 - `model` defines the specific spatio temporal model to be fitted. If the package is `"inla"` then the model argument should be a vector with two elements giving the spatial model, e.g. `"bym"` as the first component and the temporal model which could be one of `"iid", "ar1"` or `"none"` as the second component. In case the second component is "none" then no temporal random effects will be fitted. No temporal random effects will be fitted in case model is supplied as a singleton.
 - `formula` specifying the response and the covariates for forming the linear predictor $\eta$ in a GLKM. 
- `data` containing the data set to be used;
`family` being one of either `"binomial", "poisson"` `"gaussian"`,  `"multinomial"`,  or `"zip"`. In this illustration we only consider the first three choices. 
If the binomial family is chosen, the  `trials` argument must be provided. This should be a numeric vector containing the number of for each row of data.
- `scol`	 Either the name (character) or number of the column in the supplied data frame identifying the spatial units. The program will try to access `data[, scol]` to identify the spatial units. If this is omitted, no spatial modeling will be performed, instead an independent error GLM will be fitted using the `"CARBayes"` package. 
- `tcol`	 Like the `scol` argument but for the time identifier. Either the name (character) or number of the column in the supplied data frame identifying the time indices. The program will try to access `data[, tcol]` to identify the time points. If this is omitted, no temporal modeling will be performed.
- `W` A non-negative K by K neighborhood matrix (where K is the number of spatial units). Typically a binary specification is used, where the $jk$th element equals one if areas (j, k) are spatially close (e.g. share a common border) and is zero otherwise. The matrix can be non-binary, but each row must contain at least one non-zero entry. This argument may not need to be specified if `adj.graph` is specified instead.
- `adj.graph` Adjacency graph which may be specified instead of the adjacency matrix matrix. This argument is used if W has not been supplied. The argument W is used in case both W and adj.graph are supplied.

There are numerous other arguments specifying more details of the models and the prior distributions. Those are documented in the help file `?Bcartime`.  

 Like the `Bsptime` function, model validation is performed automatically
 by specifying the optional vector valued `validrows` argument containing the row numbers of the
 supplied data frame that should be used for model validation. As before, the user does not need to modify
 the data set for validation. This task is done by the `Bcartime` function. 
 
 
 The function  `Bcartime` automatically chooses the default prior distributions which can be modified by the many
 optional arguments, see the documentation of this function and also the `S.glm` function from `r CRANpkg("CARBayes")`.
 Three MCMC control parameters  `N, burn.in` and  `thin` determine the number of iterations, burn-in and thinning
 interval. The default values of these are 2000, 1000 and 10 respectively. In all of our analysis in this chapter,
 unless otherwise mentioned, we take these to be 120,000, 20,000 and 10 respectively.
 
## Modeling static areal unit data 
In this section we model the static `engtotals` data set. Here we 
employ the conditionally auto regressive (CAR) models for the spatial random effects.

### Logistic regression model for areal unit data 

```{r, echo=T, eval=T, message=FALSE, results='hide'}
N <- 20000
burn.in <- 10000
thin <- 10
f1 <- noofhighweeks ~ jsa + log10(houseprice) + log(popdensity) + sqrt(no2)
```

The independent logistic regression model is fitted using the following command. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M1 <- Bcartime(formula=f1,   data=engtotals, family="binomial",
trials=engtotals$nweek, N=N, burn.in = burn.in, thin=thin) 
```
The Leroux model is fitted when the additional options `scol="spaceid"` and `model="leroux"` are provided. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M1.leroux <- Bcartime(formula=f1, data=engtotals, scol="spaceid", 
model="leroux", W=Weng, family="binomial", trials=engtotals$nweek, 
N=N, burn.in = burn.in, thin=thin)
```
The BYM model is fitted by using the command: 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M1.bym <- Bcartime(formula=f1, data=engtotals, 
scol="spaceid", model="bym", W=Weng, family="binomial", 
trials=engtotals$nweek, N=N, burn.in = burn.in, thin=thin)
```
The above model fitting commands use the default `CARBayes` package. We can change the default option to `inla` as illustrated below. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M1.inla.bym <- Bcartime(formula=f1, data=engtotals, scol ="spaceid", 
model=c("bym"),  W=Weng, family="binomial", trials=engtotals$nweek,
package="inla") 
```

```{r, echo=T, eval=T, message=FALSE, results='hide'}
a <- rbind(M1$mchoice, M1.leroux$mchoice, M1.bym$mchoice)
a <- a[, -(5:6)]
a <- a[, c(2, 1, 4, 3)]
b <- M1.inla.bym$mchoice[1:4]
b <- b[c(2, 1, 4, 3)]
a <- rbind(a, b)
rownames(a) <- c("Independent", "Leroux", "BYM", "INLA-BYM")
colnames(a) <- c("DIC", "pDIC", "WAIC", "pWAIC") 
```

```{r m1mchoice, echo=FALSE, eval=TRUE}
knitr::kable(round(a, 2),  caption = "Model choice statistics for the binomial model fitted to the engtotals data set")
```


### Poisson regression model (disease mapping) for areal unit data 

Below we set the regression model formula. The MCMC control parameters are assumed to be the same as before.  
```{r, echo=T, eval=T}
f2 <-  covid ~ offset(logEdeaths) + jsa + log10(houseprice) + log(popdensity) + sqrt(no2) 
```
The model fitting commands are very similar to the ones for fitting logistic regression models. The differences are that we change the `family` argument and instead of the `trials` argument we provide an offset column to take care of the expected number of deaths. Here are the code lines: 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
M2 <- Bcartime(formula=f2, data=engtotals, family="poisson",
              N=N, burn.in = burn.in, thin=thin)

M2.leroux <- Bcartime(formula=f2, data=engtotals,
            scol="spaceid",  model="leroux",  family="poisson", W=Weng,
            N=N, burn.in = burn.in, thin=thin)

M2.bym <- Bcartime(formula=f2, data=engtotals,
                   scol="spaceid",  model="bym",  family="poisson", W=Weng,
                   N=N, burn.in = burn.in, thin=thin)

M2.inla.bym <- Bcartime(formula=f2, data=engtotals, scol ="spaceid",  
                        model=c("bym"), family="poisson", 
                        W=Weng, offsetcol="logEdeaths", link="log", 
                          package="inla") 

```
These model fitted objects  can be explored as before. The following table reports the model choice statistics. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
a <- rbind(M2$mchoice, M2.leroux$mchoice, M2.bym$mchoice)
a <- a[, -(5:6)]
a <- a[, c(2, 1, 4, 3)]
b <- M2.inla.bym$mchoice[1:4]
b <- b[c(2, 1, 4, 3)]
a <- rbind(a, b)
rownames(a) <- c("Independent", "Leroux", "BYM",   "INLA-BYM")
colnames(a) <- c("DIC", "pDIC", "WAIC", "pWAIC") 
```

```{r m2mchoice, echo=FALSE, eval=TRUE}
knitr::kable(round(a, 2),  caption = "Model choice statistics for the Poisson model fitted to the engtotals data set")
```


### Normal regression model for areal unit data 
Below we set the regression model formula. The MCMC control parameters are assumed to be the same as before.  
```{r, echo=T, eval=T}
f3 <-  sqrt(no2) ~  jsa + log10(houseprice) + log(popdensity) 
```

```{r, echo=T, eval=T, message=FALSE, results='hide'}
M3 <- Bcartime(formula=f3, data=engtotals, family="gaussian",
               N=N, burn.in = burn.in, thin=thin)

M3.leroux <- Bcartime(formula=f3, data=engtotals,
                      scol="spaceid",  model="leroux",  family="gaussian", W=Weng,
                      N=N, burn.in = burn.in, thin=thin)


M3.inla.bym <- Bcartime(formula=f3, data=engtotals, scol ="spaceid",  
                        model=c("bym"), family="gaussian", 
                        W=Weng,  package="inla") 

```
These model fitted objects  can be explored as before. The following table reports the model choice statistics. 
```{r, echo=T, eval=T, message=FALSE, results='hide'}
a <- rbind(M3$mchoice, M3.leroux$mchoice)
a <- a[, -(5:6)]
b <- M3.inla.bym$mchoice[1:4]
b <- b[c(2, 1, 4, 3)]
a <- rbind(a, b)
rownames(a) <- c("Independent", "Leroux",  "INLA-BYM")
colnames(a) <- c("DIC", "pDIC", "WAIC", "pWAIC") 
```

```{r m3mchoice, echo=FALSE, eval=TRUE}
knitr::kable(round(a, 2),  caption = "Model choice statistics for the normal regression model fitted to the engtotals data set")
```


## Modeling temporal areal unit data 

 The data set used in this example is the `engdeaths` data set described earlier. 
 In this section we will modify the `Bcartime` commands presented earlier to fit all the
 spatio-temporal models discussed in Chapter 10 of @Sahubook. We will illustrate model fitting, choice and validation
 using the binomial, Poisson and normal distribution based models as before in the previous section. The user does not need to
 write any direct code for fitting the models using the `r CRANpkg("CARBayesST")` package. The `Bcartime` function does this
 automatically and returns the fitted model object in its entirety and in addition, performs model validation for  the
 named rows of the supplied data frame as passed on by the `validrows` argument. 
 
 
 The previously documented arguments  of  `Bcartime` for spatial model fitting remain the same for the
 corresponding spatio-temporal models. For example, the arguments
 `formula, family, trials, scol` and `W` are unchanged  in spatial-temporal model fitting. The `data` argument
 is changed to the spatio-temporal data set `data=engdeaths`. We keep the MCMC control parameters `N, burn.in` and
 `thin` to be same as before.

 The additional arguments are `tcol`, similar to `scol`,  which identifies the temporal indices. Like the
 `scol` argument this may be specified as a column name or number in the supplied data frame.  
 The  `package` argument must be specified as  `package="CARBayesST"` to change the default
 `CARBayes` package. The model argument should be changed to one of four models, `"linear", "anova", "sepspatial"` and
 `"ar"`. Other possibilities for this argument are 
 `"localised",  `"multilevel"` and  `"dissimilarity"`, but those are not illustrated here. 
 For the sake of brevity it is undesirable to report parameter estimates  of all the models. 
 Instead, below we report only selected results. 
 
### Spatio-temporal GLM fitting with binomial distribution

 For the binomial model the response variable is  `highdeathsmr` which is a binary variable
 taking the value 1 if the SMR for death is larger than 1 in that week and in that local authority. Consequently,
 the number of trials is set at the constant value 1 by setting:
```{r, echo=T, eval=T}
nweek <- rep(1, nrow(engdeaths))
```
 The right hand side of the mode regression formula is same as before: 
```{r}
f1 <- highdeathsmr ~  jsa + log10(houseprice) + log(popdensity) 
```
The basic model fitting command for fitting the linear trend model is: 
```{r, echo=T, eval=F}
M1st <- Bcartime(formula=f1, data=engdeaths, scol=scol, tcol=tcol, trials=nweek, 
W=Weng, model="linear", family="binomial", package="CARBayesST",  N=N,
burn.in=burn.in, thin=thin)
```
 To fit the other models we simply change the  `model` argument to one of
 `"anova", "sepspatial"` and `"ar"`. For the choice  `"anova"` an additional
 argument `interaction=F` may be supplied to suppress the interaction term.
 For the `"ar"` model an additional argument `AR=2` may be provided to opt for a second order auto regressive model. The model fitting commands,   
 not shown here, produce the following table: 
 \begin{tabular}{rrrrr}
  \hline
 & DIC & pDIC & WAIC & pWAIC \\ 
  \hline
Linear & 7994.6 & 9.7 & 7994.6 & 9.8 \\ 
  Anova (Interaction) & 7981.9 & 84.8 & 7980.5 & 82.4 \\ 
  Anova (No Interaction) & 7981.2 & 17.2 & 7981.2 & 17.1 \\ 
  Separable & 7995.3 & 92.5 & 7961.8 & 58.9 \\ 
  AR(1) & 7433.7 & 1918.9 & 7266.0 & 1401.1 \\ 
   \hline
\end{tabular}
Clearly, the AR model is chosen by both the DIC and WAIC.
The parameter estimates of the chosen AR model are provided below: 
\begin{tabular}{rrrr}
  \hline
 & Median & 2.5\% & 97.5\% \\ 
  \hline
(Intercept) & --3.2285 & --6.9051 & 0.1949 \\ 
  jsa & 0.3951 & -0.1063 & 0.9401 \\ 
  log10(house price) & 0.1885 & --0.4644 & 0.8679 \\ 
  log(pop density) & 0.1536 & 0.0679 & 0.2496 \\ 
  $\tau^2$ & 7.7510 & 4.5113 & 15.2136 \\ 
  $\rho_S$ & 0.6329 & 0.4504 & 0.7817 \\ 
  $\rho_T$ & 0.0015 & 0.0001 & 0.0080 \\ 
   \hline
\end{tabular}


###  Spatio-temporal GLM  fitting with Poisson distribution


 For fitting the Poisson distribution based model we take the response variable as the column  `covid`, 
 which records the number of Covid-19 deaths, of the  `engdeaths` data set.
 The column `logEdeaths` is used as an offset in the model with the default log link function.

 The formula argument for the regression part of the linear predictor is chosen to be the same as the
 one used by @SahuBohning2021 for a similar data set. The formula contains, in addition to the
 thee socio-economic variables, the log of the SMR for the number cases in the current week and
 three previous weeks denoted by `n0, n1, n2` and  `n3`. The formula is given below:
```{r}
f2 <-  covid ~ offset(logEdeaths) + jsa + log10(houseprice) + log(popdensity) + n0 + n1 + n2 + n3
```
We now fit the Poisson model by keeping  the other arguments  same
 as before in the previous Section. The command for fitting the
 temporal auto-regressive model is:
```{r}
M2st <- Bcartime(formula=f2, data=engdeaths, scol=scol, tcol=tcol,  W=Weng,
model="ar", family="poisson", package="CARBayesST", N=N, burn.in=burn.in, thin=thin)
```
The `model` argument can be changed to fit the other models. The resulting model fits are used to obtain the following model choice statistics. 
\begin{tabular}{rrrrr}
  \hline
 & DIC & p.d & WAIC & p.w \\ 
  \hline
Linear & 28957.4 & 408.4 & 29638.8 & 917.8 \\ 
  Anova (Interaction) & 26165.1 & 2091.1 & 26089.1 & 1585.8 \\ 
  Anova (No Interaction) & 28865.4 & 220.6 & 29246.7 & 537.2 \\ 
  Separable & 26186.4 & 1847.1 & 26172.9 & 1464.1 \\ 
  AR & 26159.0 & 1952.6 & 26145.7 & 1534.3 \\ 
   \hline
\end{tabular}
The parameter estimates of the chosen ANOVA model are reported below:  
\begin{tabular}{rrrr}
  \hline
 & Median & 2.5\% & 97.5\% \\ 
  \hline
(Intercept) & -3.766 & -4.511 & -2.977 \\ 
  jsa & 0.143 & 0.052 & 0.229 \\ 
  log10(houseprice) & 0.622 & 0.478 & 0.759 \\ 
  log(popdensity) & 0.054 & 0.036 & 0.071 \\ 
  n0 & 0.507 & 0.488 & 0.526 \\ 
  n1 & 0.194 & 0.171 & 0.218 \\ 
  n2 & 0.084 & 0.059 & 0.107 \\ 
  n3 & 0.063 & 0.048 & 0.078 \\ 
  $\tau^2_S$ & 0.003 & 0.001 & 0.006 \\ 
  $\tau^2_T$ & 0.015 & 0.007 & 0.031 \\ 
  $\tau^2_I$ & 0.122 & 0.111 & 0.135 \\ 
  $\rho_S$ & 0.572 & 0.114 & 0.933 \\ 
  $\rho_T$ & 0.787 & 0.346 & 0.972 \\ 
   \hline
\end{tabular}
To  investigate the differences in  model choice by DIC and WAIC we test both models for validation.  We randomly select 10\% data rows for validation 
by issuing the command
```{r}
vs <- sample(nrow(engdeaths), 0.1*nrow(engdeaths))
```
Now we refit the Anova and AR models with the additional argument `validrows = vs`.
The validation statistics reported below show that the AR model is indeed slightly worse than the chosen Anova model.  
\begin{tabular}{rrrr}
  \hline
 & rmse & mae & cvg \\ 
  \hline
Anova & 5.55 & 2.77 & 96.65 \\ 
  AR & 5.82 & 2.78 & 96.49 \\ 
   \hline
\end{tabular}



### Spatio-temporal GLM  fitting with normal distribution}
 
 We now illustrate spatio-temporal random effects  fitting of the model 
 `f3` for NO$_2$. We fit the `"gaussian"` family model but keep the  other arguments  same
 as before in the previous two sections for fitting binomial and Poisson models.
 The command for fitting the temporal auto-regressive model is:
```{r}
M3st <- Bcartime(formula=f3, data=engdeaths, scol=scol, tcol=tcol, 
W=Weng, model="ar", family="gaussian", package="CARBayesST", 
N=N, burn.in=burn.in, thin=thin)
```
The following table produces the model choice statistics.  

\begin{tabular}{rrrrr}
  \hline
 & DIC & pDIC & WAIC & pWAIC\\ 
  \hline
Linear & 12821.1 & 34.1 & 12822.3 & 35.1 \\ 
  Anova (Interaction) & 12632.3 & 42.5 & 12632.8 & 42.7 \\ 
  Anovano (No Interaction) & 12632.3 & 42.5 & 12632.8 & 42.7 \\ 
  AR & 11526.7 & 1794.0 & 11490.1 & 1453.1 \\ 
   \hline
\end{tabular}
 The AR model is the
best according to  both DIC and WAIC although it receives much higher penalty. The parameter estimates of the
chosen model are presented below: 
\begin{tabular}{rrrr}
  \hline
 & Median & 2.5\% & 97.5\% \\ 
  \hline
(Intercept) & --1.1211 & --2.0041 & --0.2193 \\ 
  jsa & 0.0063 & --0.1022 & 0.1149 \\ 
  log10(houseprice) & 0.7511 & 0.5871 & 0.9113 \\ 
  log(popdensity) & 0.1136 & 0.0947 & 0.1322 \\ 
  $\tau^2$ & 0.3625 & 0.3034 & 0.4271 \\ 
  $\nu^2$ & 0.2775 & 0.2563 & 0.2975 \\ 
  $\rho_S$ & 0.9291 & 0.8824 & 0.9620 \\ 
  $\rho_T$ & 0.0070 & 0.0003 & 0.0344 \\ 
   \hline
\end{tabular}
 Model validation, not done here,
can be performed by supplying the `validrows` argument.   



# Discussion 

The `bmstdr` package enables the user to use a plurality of `R` packages for fitting spatial and spatio-temporal models. The applied researcher is thus encouraged to explore other, possibly richer,  solutions to their problems offered by  other packages. 

There are several limitations of the `bmstdr` package. The first one is that it does not allow modeling of  point reference spatial data which are discrete. Such modeling is challenging and at the moment only a few packages such as `INLA` can be used. Bayesian modeling implementation of discrete point reference spatial and spatio-temporal will be considered in future versions. The `bmstdr` package also offers only a limited number of models using the `rstan` and `INLA` packages. Spatio-temporal models offering richer structures can be fitted using these two and other `R` packages. Such modeling will also be considered in future version updates.  

# References 
